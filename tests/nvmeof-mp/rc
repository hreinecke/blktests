#!/bin/bash
# SPDX-License-Identifier: GPL-2.0+
# Copyright (c) 2018 Western Digital Corporation or its affiliates

. common/rc
. common/multipath-over-rdma
. common/nvmet

set -o errexit

namespace=(1)
elevator=none
nvme_subsysnqn="nvme-test"
nvme_port=7777
nvme_trtype=${nvme_trtype:-"rdma"}
ini_timeout=1

group_requires() {
	local m name p required_modules

	_have_configfs || return
	required_modules=(
		null_blk
		rdma_cm
		ib_ipoib
		ib_umad
		nvme-${nvme_trtype}
		nvmet-${nvme_trtype}
		rdma_rxe
	)
	_have_modules "${required_modules[@]}" || return

	for p in mkfs.ext4 mkfs.xfs nvme pidof rdma fio; do
		_have_program "$p" || return
	done

	_have_root || return
}

# Log out, set dm use_blk_mq parameter to $1 and log in.
use_blk_mq() {
	trapcmd="echo use_blk_mq \$\* failed >> $FULL"
	trap "$trapcmd" EXIT
	log_out
	start_client
	log_in
	trap - EXIT
	return 0
}

log_in() {
	local i ipv4_addr loginparams

	if [ ! -c /dev/nvme-fabrics ]; then
		return false
	fi
	for i in $(rdma_network_interfaces); do
		ipv4_addr=$(get_ipv4_addr "$i")
		if [ -n "${ipv4_addr}" ]; then
			loginparams="transport=${nvme_trtype},traddr=${ipv4_addr},trsvcid=${nvme_port},nqn=$nvme_subsysnqn"
			echo "Login parameters: $loginparams" >>"$FULL"
			{
				echo -n "$loginparams" > /dev/nvme-fabrics
			} 2>>"$FULL"
		fi
	done
}

log_out() {
	local c

	for c in /sys/class/nvme-fabrics/ctl/*/delete_controller; do
		[ -e "$c" ] && echo 1 > "$c" &
	done
	wait
}

# Simulate network failures for device $1 during $2 seconds.
simulate_network_failure_loop() {
	local d dev="$1" duration="$2" deadline i rc=0 sf

	[ -e "$dev" ] || return $?
	[ -n "$duration" ] || return $?
	deadline=$(($(_uptime_s) + duration))
	while [ $rc = 0 ]; do
		sleep_until 5 ${deadline} || break
		for s in /sys/class/nvme-subsystem/nvme-subsys* ; do
			[ -e "$s" ] || continue
			[ "$(basename $s)" = "$dev" ] && continue
			for c in $s/nvme* ; do
				[ -e "$c" ] || continue
				cdev="$(basename $c)"
				[ "$cdev" = "${dev}" ] && continue
				echo 1 > /sys/class/nvme/$cdev/reset_controller
			done
		done
	done 2>>"$FULL"
}

start_nvme_client() {
	modprobe nvme-core dyndbg=+pmf
	modprobe nvme dyndbg=+pmf
	modprobe nvme-fabrics dyndbg=+pmf
	modprobe nvme-${nvme_trtype} dyndbg=+pmf
	mkdir -p "$(mountpoint 0)"
	udevadm settle
	if [ ! -c /dev/nvme-fabrics ]; then
		echo "Error:  /dev/nvme-fabrics not available"
	fi
}

stop_nvme_client() {
	unload_module nvme-${nvme_trtype} || return $?
	unload_module nvme-fabrics || return $?
	# Ignore nvme and nvme-core unload errors - this test may be run on a
	# system equipped with one or more NVMe SSDs.
	unload_module nvme >&/dev/null
	unload_module nvme-core >&/dev/null
	return 0
}

# Load the initiator kernel driver with kernel module parameters $1..$n.
start_client() {
	start_nvme_client
}

stop_client() {
	stop_nvme_client
}

start_nvme_target() {
	local d i ipv4_addr num_ports=0

	echo "Configuring NVMe target driver ..." >>"$FULL"
	_setup_nvmet
	sleep .1

	_create_nvmet_subsystem "${nvme_subsysnqn}" /dev/nullb0

	for i in $(rdma_network_interfaces); do
		ipv4_addr=$(get_ipv4_addr "$i")
		[ -n "${ipv4_addr}" ] || continue
		echo "Configuring $p with address $ipv4_addr as an NVMeOF target port" \
	     >>"$FULL"

		port="$(_create_nvmet_port "${nvme_trtype}" "${ipv4_addr}" ipv4 "${nvme_port}")"
		_add_nvmet_subsys_to_port "${port}" "${nvme_subsysnqn}"
		((num_ports++)) || true
	done
	if [[ $num_ports = 0 ]]; then
		echo "No NVMeOF target ports"
		return
	fi
	echo "Configured NVMe target driver"
}

start_target() {
	start_nvme_target
}

stop_target() {
	_exit_null_blk
}

shutdown_client() {
	log_out
	stop_client
}

# Set up test configuration
setup() {
	setup_test "$PWD/tests/nvmeof-mp/multipath.conf"
}
